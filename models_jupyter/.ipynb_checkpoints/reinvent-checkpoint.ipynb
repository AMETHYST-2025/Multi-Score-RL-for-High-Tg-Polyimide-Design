{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to run REINVENT\n",
    "\n",
    "Clone the reinvent-benchmarking github repo. More details found there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!git clone https://github.com/gkwt/reinvent-benchmarking.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define fitness function from tartarus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the fitness function into the `custom.py` file of the repo. Default is the logP fitness function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "ROOT_DIR = '..'\n",
    "sys.path.append(ROOT_DIR)\n",
    "sys.path.append('reinvent-benchmarking')\n",
    "\n",
    "from tartarus import pce\n",
    "\n",
    "def fitness_function(smi: str):\n",
    "    dipole, hl_gap, lumo, obj, pce_1, pce_2, sas = pce.get_properties(smi)\n",
    "    return pce_1 - sas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-11 18:05:19.475951: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1749665119.496227  371755 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1749665119.504329  371755 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1749665119.533760  371755 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749665119.533804  371755 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749665119.533808  371755 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749665119.533813  371755 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-06-11 18:05:19.542313: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/jovyan/RL-GraphINVENT/RL-GraphINVENT-scores/my-conda-envs/RL-GraphINVENT/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "I0000 00:00:1749665125.691716  371755 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43720 MB memory:  -> device: 0, name: NVIDIA A40, pci bus id: 0000:01:01.0, compute capability: 8.6\n",
      "2025-06-11 18:05:26.474577: W external/local_xla/xla/service/gpu/llvm_gpu_backend/default/nvptx_libdevice_path.cc:40] Can't find libdevice directory ${CUDA_DIR}/nvvm/libdevice. This may result in compilation or runtime failures, if the program we try to run uses routines from libdevice.\n",
      "Searched for CUDA in the following directories:\n",
      "  ./cuda_sdk_lib\n",
      "  ipykernel_launcher.runfiles/cuda_nvcc\n",
      "  ipykern/cuda_nvcc\n",
      "  \n",
      "  /usr/local/cuda\n",
      "  /opt/cuda\n",
      "  /home/jovyan/RL-GraphINVENT/RL-GraphINVENT-scores/my-conda-envs/RL-GraphINVENT/lib/python3.12/site-packages/tensorflow/python/platform/../../../nvidia/cuda_nvcc\n",
      "  /home/jovyan/RL-GraphINVENT/RL-GraphINVENT-scores/my-conda-envs/RL-GraphINVENT/lib/python3.12/site-packages/tensorflow/python/platform/../../../../nvidia/cuda_nvcc\n",
      "  /home/jovyan/RL-GraphINVENT/RL-GraphINVENT-scores/my-conda-envs/RL-GraphINVENT/lib/python3.12/site-packages/tensorflow/python/platform/../../cuda\n",
      "  /home/jovyan/RL-GraphINVENT/RL-GraphINVENT-scores/my-conda-envs/RL-GraphINVENT/lib/python3.12/site-packages/tensorflow/python/platform/../../../../../..\n",
      "  /home/jovyan/RL-GraphINVENT/RL-GraphINVENT-scores/my-conda-envs/RL-GraphINVENT/lib/python3.12/site-packages/tensorflow/python/platform/../../../../../../..\n",
      "  .\n",
      "You can choose the search directory by setting xla_gpu_cuda_data_dir in HloModule's DebugOptions.  For most apps, setting the environment variable XLA_FLAGS=--xla_gpu_cuda_data_dir=/path/to/cuda will work.\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import pandas as pd\n",
    "#import data_structs as ds\n",
    "from data_structs_n import canonicalize_smiles_from_file, construct_vocabulary, write_smiles_to_file\n",
    "from train_prior import pretrain\n",
    "from train_agent import train_agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the dataset and vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data_structs\n",
    "#print(data_structs.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../datasets\n",
      "                                                  SMILES     Tg\n",
      "0      Ic1ccc(nc1)Cc1ccc2c(c1)cc(cc2)Cc1ccc(cn1)N1C(=...  508.0\n",
      "1      O=C1c2cc(ccc2C(=O)N1c1ccc(c(c1Cl)Cl)S(=O)(=O)c...  641.0\n",
      "2      Ic1cc(cc(c1)C(=O)O)C(=O)c1ccc2c(c1)ccc(c2)C(=O...  602.0\n",
      "3      Clc1cc(cc(c1)C(C(F)(F)F)(C(F)(F)F)c1c(C)cc(cc1...  548.0\n",
      "4      Cc1cc(Sc2ccc(nc2)Sc2cc(C)c(c(c2)C)I)cc(c1N1C(=...  502.0\n",
      "...                                                  ...    ...\n",
      "49995  Cc1cc(Cc2ccc(cc2)c2ccc(cc2)Cc2cc(C)c(c(c2)C)I)...  506.0\n",
      "49996  Cc1cc(Cc2ccc(cc2)c2ccc(cc2)Cc2cc(C)c(c(c2)C)I)...  506.0\n",
      "49997  Cc1cc(Cc2ccc(cc2)c2ccc(cc2)Cc2cc(C)c(c(c2)C)I)...  506.0\n",
      "49998  Cc1cc(Cc2ccc(cc2)c2ccc(cc2)Cc2cc(C)c(c(c2)C)I)...  505.0\n",
      "49999  Cc1cc(Cc2ccc(cc2)c2ccc(cc2)Cc2cc(C)c(c(c2)C)I)...  505.0\n",
      "\n",
      "[50000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "data_path = os.path.join(ROOT_DIR, 'datasets')\n",
    "print(data_path)\n",
    "filename = 'Polyimides_synthetic.csv'  #'hce.csv'\n",
    "sep = ','\n",
    "header = 'infer'\n",
    "smile_name = 'SMILES' #'smiles'\n",
    "\n",
    "# dataset load\n",
    "fname = os.path.join(data_path, filename)\n",
    "data = pd.read_csv(fname, sep=sep, header=header)\n",
    "\n",
    "headers =  [\"SMILES\", \"Tg\"]\n",
    "data.columns = headers\n",
    "\n",
    "data = data[headers][:50000]\n",
    "print(data)\n",
    "\n",
    "smiles = data[smile_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading smiles...\n",
      "0 lines processed.\n",
      "5000 lines processed.\n",
      "10000 lines processed.\n",
      "15000 lines processed.\n",
      "20000 lines processed.\n",
      "25000 lines processed.\n",
      "30000 lines processed.\n",
      "35000 lines processed.\n",
      "40000 lines processed.\n",
      "45000 lines processed.\n",
      "50000 SMILES retrieved\n",
      "Constructing vocabulary...\n",
      "Number of characters: 25\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isdir('data'):\n",
    "    os.mkdir('data')\n",
    "\n",
    "# create smi file\n",
    "with open(os.path.join('data', 'data.smi'), 'w') as f:\n",
    "    for smi in smiles:\n",
    "        f.write(smi+'\\n')\n",
    "\n",
    "smiles_file = 'data/data.smi'\n",
    "print(\"Reading smiles...\")\n",
    "smiles_list = canonicalize_smiles_from_file(smiles_file)\n",
    "print(\"Constructing vocabulary...\")\n",
    "voc_chars = construct_vocabulary(smiles_list)\n",
    "write_smiles_to_file(smiles_list, \"data/mols_filtered.smi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrain the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 44.46 GiB of which 832.00 KiB is free. Process 3536047 has 44.45 GiB memory in use. Of the allocated memory 1.44 GiB is allocated by PyTorch, and 10.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOutOfMemoryError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m verbose = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m      3\u001b[39m train_ratio = \u001b[32m0.8\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43mpretrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_ratio\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_ratio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrestore_from\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdata/Prior_PI_50k_epochs_8.ckpt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Tartarus_ChaRNN/Tartarus/models_jupyter/reinvent-benchmarking/train_prior.py:66\u001b[39m, in \u001b[36mpretrain\u001b[39m\u001b[34m(num_epochs, verbose, train_ratio, restore_from)\u001b[39m\n\u001b[32m     63\u001b[39m seqs = batch.long()\n\u001b[32m     65\u001b[39m \u001b[38;5;66;03m# Calculate loss\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m log_p, _ = \u001b[43mPrior\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlikelihood\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseqs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     67\u001b[39m loss = - log_p.mean()\n\u001b[32m     69\u001b[39m \u001b[38;5;66;03m# Calculate gradients and take a step\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Tartarus_ChaRNN/Tartarus/models_jupyter/reinvent-benchmarking/model.py:64\u001b[39m, in \u001b[36mRNN.likelihood\u001b[39m\u001b[34m(self, target)\u001b[39m\n\u001b[32m     62\u001b[39m entropy = Variable(torch.zeros(batch_size))\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(seq_length):\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m     logits, h = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     65\u001b[39m     log_prob = F.log_softmax(logits, dim=-\u001b[32m1\u001b[39m)\n\u001b[32m     66\u001b[39m     prob = F.softmax(logits, dim=-\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/RL-GraphINVENT/RL-GraphINVENT-scores/my-conda-envs/RL-GraphINVENT/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/RL-GraphINVENT/RL-GraphINVENT-scores/my-conda-envs/RL-GraphINVENT/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Tartarus_ChaRNN/Tartarus/models_jupyter/reinvent-benchmarking/model.py:24\u001b[39m, in \u001b[36mMultiGRU.forward\u001b[39m\u001b[34m(self, x, h)\u001b[39m\n\u001b[32m     22\u001b[39m x = \u001b[38;5;28mself\u001b[39m.embedding(x)\n\u001b[32m     23\u001b[39m h_out = Variable(torch.zeros(h.size()))\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m x = h_out[\u001b[32m0\u001b[39m] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgru_1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m x = h_out[\u001b[32m1\u001b[39m] = \u001b[38;5;28mself\u001b[39m.gru_2(x, h[\u001b[32m1\u001b[39m])\n\u001b[32m     26\u001b[39m x = h_out[\u001b[32m2\u001b[39m] = \u001b[38;5;28mself\u001b[39m.gru_3(x, h[\u001b[32m2\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/RL-GraphINVENT/RL-GraphINVENT-scores/my-conda-envs/RL-GraphINVENT/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/RL-GraphINVENT/RL-GraphINVENT-scores/my-conda-envs/RL-GraphINVENT/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/RL-GraphINVENT/RL-GraphINVENT-scores/my-conda-envs/RL-GraphINVENT/lib/python3.12/site-packages/torch/nn/modules/rnn.py:1813\u001b[39m, in \u001b[36mGRUCell.forward\u001b[39m\u001b[34m(self, input, hx)\u001b[39m\n\u001b[32m   1810\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1811\u001b[39m     hx = hx.unsqueeze(\u001b[32m0\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_batched \u001b[38;5;28;01melse\u001b[39;00m hx\n\u001b[32m-> \u001b[39m\u001b[32m1813\u001b[39m ret = \u001b[43m_VF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgru_cell\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1814\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1815\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1816\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight_ih\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1817\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight_hh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1818\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias_ih\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1819\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias_hh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1820\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1822\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_batched:\n\u001b[32m   1823\u001b[39m     ret = ret.squeeze(\u001b[32m0\u001b[39m)\n",
      "\u001b[31mOutOfMemoryError\u001b[39m: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 44.46 GiB of which 832.00 KiB is free. Process 3536047 has 44.45 GiB memory in use. Of the allocated memory 1.44 GiB is allocated by PyTorch, and 10.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "num_epochs = 1 #100\n",
    "verbose = False\n",
    "train_ratio = 0.8\n",
    "pretrain(num_epochs=num_epochs, verbose=verbose, train_ratio=train_ratio) #, restore_from = \"data/Prior_PI_50k_epochs_8.ckpt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start climbing algorithm for REINVENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tartarus import docking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_agent(\n",
    "    scoring_function='tanimoto', #'Tg_score'\n",
    "    batch_size = 500,\n",
    "    n_steps = 10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda list python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run ./reinvent-benchmarking/Pred_Tg/PI_Tg_Pred.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda list sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install sentence-transformers==3.4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install sentence-transformers==3.4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip show transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install transformers==4.28.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SMILES</th>\n",
       "      <th>Tg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33553</th>\n",
       "      <td>O=C(c1ccc2c(c1)C(=O)N(C2=O)I)c1ccc(cn1)C(c1ccc...</td>\n",
       "      <td>455.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9427</th>\n",
       "      <td>Clc1cc(I)cc(c1)Sc1ccc(cc1C)Sc1cc(Cl)cc(c1)N1C(...</td>\n",
       "      <td>455.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>Ic1cc(cc(c1)C(F)(F)F)C(=O)c1ccc2c(c1)[nH]c1c2c...</td>\n",
       "      <td>515.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12447</th>\n",
       "      <td>Cc1ccc(cc1Cc1cc(C)c(c(c1)C)c1c(C)cc(cc1C)Cc1cc...</td>\n",
       "      <td>523.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39489</th>\n",
       "      <td>Ic1ccc(nc1)C(c1ccc2c(c1)ccc(c2)C(c1ccc(cn1)N1C...</td>\n",
       "      <td>466.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33582</th>\n",
       "      <td>Ic1ccc(c(c1)Oc1cc(Oc2ccc(c(c2)N2C(=O)c3c(C2=O)...</td>\n",
       "      <td>479.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31702</th>\n",
       "      <td>Ic1ccc(c(c1)C)Cc1ccc2c(c1)c1cc(ccc1C2(C)C)Cc1c...</td>\n",
       "      <td>510.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38237</th>\n",
       "      <td>Ic1ccc(c(c1)C(C(F)(F)F)(C(F)(F)F)c1ccc(c(c1)Cl...</td>\n",
       "      <td>497.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22358</th>\n",
       "      <td>Clc1cc(cc(c1)C(C(F)(F)F)(C(F)(F)F)c1c(C)cc(cc1...</td>\n",
       "      <td>548.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48246</th>\n",
       "      <td>Ic1cc(C)c(c(c1)C)Oc1ccc(nc1)Oc1c(C)cc(cc1C)N1C...</td>\n",
       "      <td>538.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  SMILES     Tg\n",
       "33553  O=C(c1ccc2c(c1)C(=O)N(C2=O)I)c1ccc(cn1)C(c1ccc...  455.0\n",
       "9427   Clc1cc(I)cc(c1)Sc1ccc(cc1C)Sc1cc(Cl)cc(c1)N1C(...  455.0\n",
       "199    Ic1cc(cc(c1)C(F)(F)F)C(=O)c1ccc2c(c1)[nH]c1c2c...  515.0\n",
       "12447  Cc1ccc(cc1Cc1cc(C)c(c(c1)C)c1c(C)cc(cc1C)Cc1cc...  523.0\n",
       "39489  Ic1ccc(nc1)C(c1ccc2c(c1)ccc(c2)C(c1ccc(cn1)N1C...  466.0\n",
       "...                                                  ...    ...\n",
       "33582  Ic1ccc(c(c1)Oc1cc(Oc2ccc(c(c2)N2C(=O)c3c(C2=O)...  479.0\n",
       "31702  Ic1ccc(c(c1)C)Cc1ccc2c(c1)c1cc(ccc1C2(C)C)Cc1c...  510.0\n",
       "38237  Ic1ccc(c(c1)C(C(F)(F)F)(C(F)(F)F)c1ccc(c(c1)Cl...  497.0\n",
       "22358  Clc1cc(cc(c1)C(C(F)(F)F)(C(F)(F)F)c1c(C)cc(cc1...  548.0\n",
       "48246  Ic1cc(C)c(c(c1)C)Oc1ccc(nc1)Oc1c(C)cc(cc1C)N1C...  538.0\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from Pred_Tg.PI_Tg_Pred import Pred_PI_Tg\n",
    "import numpy as np\n",
    "# Sous-échantillon du trainset pour équilibrer la visualisation, 50 k trop grand !\n",
    "data_sample = data.sample(n=2000, random_state=42)\n",
    "data_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluation de la performance du modele predictif\n",
    "#data_sample['Tg_pred']=data_sample[\"SMILES\"].apply(Pred_PI_Tg) #\n",
    "#rmse = np.sqrt(np.mean((data_sample['Tg_pred'] - data_sample['Tg']) ** 2))\n",
    "#mae = np.mean(np.abs(data_sample['Tg_pred'] - data_sample['Tg']))\n",
    "#print(rmse, mae) #47.47540132795242 30.640225479125977"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.metrics import r2_score\n",
    "#r2 = r2_score(data_sample['Tg'], data_sample['Tg_pred'])\n",
    "#print(r2) #0.30103430066668935"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Pred_Tg.PI_Tg_Pred import run_PolyBERT, finetune_PolyBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 smiles   fitness     score  \\\n",
      "0     Cc1cc(S(=O)(=O)c2ccc(S(=O)(=O)c3cc(C)c(N4C(=O)...  0.296010  0.214925   \n",
      "1     Cc1cc(C(c2ccc(C(c3c(C)cc(I)cc3C)(C(F)(F)F)C(F)...  0.331492  0.330634   \n",
      "2     O=c1c2cc3c(=O)n(-c4ccc(Oc5ccc(I)cn5)nc4)c(=O)c...  0.321152  0.297752   \n",
      "3     Cc1ccc(C(c2ccc(C(c3cc(I)ccc3C)(C(F)(F)F)C(F)(F...  0.000000 -0.678468   \n",
      "4     Cc1ccc(N2C(=O)c3cccc(-c4ccc5c(c4)C(=O)N(I)C5=O...  0.423963  0.584891   \n",
      "...                                                 ...       ...       ...   \n",
      "4737  Cc1c(I)cccc1Sc1ccc(Sc2cccc(-n3c(=O)c4cc5cc4c(=...  0.000000 -0.643401   \n",
      "4738  Cc1cc(-c2cc(C)c(Sc3ccc(N4C(=O)c5ccc(-c6ccc7c(c...  0.386343  0.353131   \n",
      "4739  Cc1c(Sc2ccc(N3C(=O)c4ccc(-c5ccc6c(c5)C(=O)N(I)...  0.000000 -0.643401   \n",
      "4740  Cc1cc(I)cc(C)c1Sc1ccc(Cc2c(C)cc(N3C(=O)c4ccc(-...  0.385627  0.351291   \n",
      "4741  Cc1cc(C(c2ccc(-c3ccc(C(c4ccc(-n5c(=O)cn6c(=O)c...  0.000000 -0.643401   \n",
      "\n",
      "      generation  \n",
      "0            0.0  \n",
      "1            0.0  \n",
      "2            0.0  \n",
      "3            0.0  \n",
      "4            0.0  \n",
      "...          ...  \n",
      "4737         9.0  \n",
      "4738         9.0  \n",
      "4739         9.0  \n",
      "4740         9.0  \n",
      "4741         9.0  \n",
      "\n",
      "[4742 rows x 4 columns]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'data_sample' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m PI_generation = pd.read_csv(\u001b[33m\"\u001b[39m\u001b[33mdata/results/run_PI_50k_11_Juin_2025/results.csv\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(PI_generation)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m data_sample[\u001b[33m'\u001b[39m\u001b[33mPB\u001b[39m\u001b[33m'\u001b[39m]=\u001b[43mdata_sample\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33mSMILES\u001b[39m\u001b[33m\"\u001b[39m].apply(finetune_PolyBERT) \u001b[38;5;66;03m# (trainset)\u001b[39;00m\n\u001b[32m     10\u001b[39m data_sample[\u001b[33m'\u001b[39m\u001b[33mPB\u001b[39m\u001b[33m'\u001b[39m] = data_sample[\u001b[33m'\u001b[39m\u001b[33mPB\u001b[39m\u001b[33m'\u001b[39m].apply(\u001b[38;5;28meval\u001b[39m)\n\u001b[32m     11\u001b[39m data_sample[\u001b[33m'\u001b[39m\u001b[33mPB\u001b[39m\u001b[33m'\u001b[39m] = data_sample[\u001b[33m'\u001b[39m\u001b[33mPB\u001b[39m\u001b[33m'\u001b[39m].apply(np.array)\n",
      "\u001b[31mNameError\u001b[39m: name 'data_sample' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "PI_generation = pd.read_csv(\"data/results/run_PI_50k_11_Juin_2025/results.csv\")\n",
    "print(PI_generation)\n",
    "\n",
    "data_sample['PB']=data_sample[\"SMILES\"].apply(finetune_PolyBERT) # (trainset)\n",
    "data_sample['PB'] = data_sample['PB'].apply(eval)\n",
    "data_sample['PB'] = data_sample['PB'].apply(np.array)\n",
    "\n",
    "PI_generation['PB'] = PI_generation[\"smiles\"].apply(finetune_PolyBERT) # un peu plus de 400 par generation, [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0] \n",
    "PI_generation['PB'] = PI_generation['PB'].apply(eval)\n",
    "PI_generation['PB'] = PI_generation['PB'].apply(np.array)\n",
    "\n",
    "# Liste des générations à tracer\n",
    "generations = [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0]\n",
    "\n",
    "# Prépare la figure\n",
    "fig, axes = plt.subplots(2, 5, figsize=(25, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, gen in enumerate(generations):\n",
    "    ax = axes[idx]\n",
    "\n",
    "    # Extraire les embeddings\n",
    "    X_train = np.vstack(data_sample['PB'].values)\n",
    "    X_gen = np.vstack(PI_generation[PI_generation['generation'] == gen]['PB'].values)\n",
    "\n",
    "    # Créer un tableau combiné\n",
    "    X = np.vstack([X_train, X_gen])\n",
    "    labels = np.array(['train'] * len(X_train) + [f'gen_{int(gen)}'] * len(X_gen))\n",
    "\n",
    "    # Projection t-SNE\n",
    "    tsne = TSNE(n_components=2, random_state=42, perplexity=30)\n",
    "    X_tsne = tsne.fit_transform(X)\n",
    "\n",
    "    # Plot\n",
    "    ax.scatter(X_tsne[labels == 'train', 0], X_tsne[labels == 'train', 1], alpha=0.3, label='Train', s=10)\n",
    "    ax.scatter(X_tsne[labels != 'train', 0], X_tsne[labels != 'train', 1], alpha=0.7, label=f'Gen {int(gen)}', s=10)\n",
    "    ax.set_title(f\"t-SNE Projection: Generation {int(gen)}\")\n",
    "    ax.legend()\n",
    "    print('ok')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:RL-GraphINVENT]",
   "language": "python",
   "name": "conda-env-RL-GraphINVENT-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
