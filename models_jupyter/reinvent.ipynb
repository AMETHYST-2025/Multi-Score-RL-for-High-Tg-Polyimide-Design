{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to run REINVENT\n",
    "\n",
    "Clone the reinvent-benchmarking github repo. More details found there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!git clone https://github.com/gkwt/reinvent-benchmarking.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define fitness function from tartarus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the fitness function into the `custom.py` file of the repo. Default is the logP fitness function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "ROOT_DIR = '..'\n",
    "sys.path.append(ROOT_DIR)\n",
    "sys.path.append('reinvent-benchmarking')\n",
    "\n",
    "from tartarus import pce\n",
    "\n",
    "def fitness_function(smi: str):\n",
    "    dipole, hl_gap, lumo, obj, pce_1, pce_2, sas = pce.get_properties(smi)\n",
    "    return pce_1 - sas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-11 18:41:15.511227: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1749667275.526648  372205 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1749667275.531558  372205 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1749667275.543231  372205 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749667275.543247  372205 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749667275.543249  372205 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749667275.543250  372205 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-06-11 18:41:15.547910: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/jovyan/RL-GraphINVENT/RL-GraphINVENT-scores/my-conda-envs/RL-GraphINVENT/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "I0000 00:00:1749667280.177756  372205 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43720 MB memory:  -> device: 0, name: NVIDIA A40, pci bus id: 0000:01:01.0, compute capability: 8.6\n",
      "2025-06-11 18:41:20.977827: W external/local_xla/xla/service/gpu/llvm_gpu_backend/default/nvptx_libdevice_path.cc:40] Can't find libdevice directory ${CUDA_DIR}/nvvm/libdevice. This may result in compilation or runtime failures, if the program we try to run uses routines from libdevice.\n",
      "Searched for CUDA in the following directories:\n",
      "  ./cuda_sdk_lib\n",
      "  ipykernel_launcher.runfiles/cuda_nvcc\n",
      "  ipykern/cuda_nvcc\n",
      "  \n",
      "  /usr/local/cuda\n",
      "  /opt/cuda\n",
      "  /home/jovyan/RL-GraphINVENT/RL-GraphINVENT-scores/my-conda-envs/RL-GraphINVENT/lib/python3.12/site-packages/tensorflow/python/platform/../../../nvidia/cuda_nvcc\n",
      "  /home/jovyan/RL-GraphINVENT/RL-GraphINVENT-scores/my-conda-envs/RL-GraphINVENT/lib/python3.12/site-packages/tensorflow/python/platform/../../../../nvidia/cuda_nvcc\n",
      "  /home/jovyan/RL-GraphINVENT/RL-GraphINVENT-scores/my-conda-envs/RL-GraphINVENT/lib/python3.12/site-packages/tensorflow/python/platform/../../cuda\n",
      "  /home/jovyan/RL-GraphINVENT/RL-GraphINVENT-scores/my-conda-envs/RL-GraphINVENT/lib/python3.12/site-packages/tensorflow/python/platform/../../../../../..\n",
      "  /home/jovyan/RL-GraphINVENT/RL-GraphINVENT-scores/my-conda-envs/RL-GraphINVENT/lib/python3.12/site-packages/tensorflow/python/platform/../../../../../../..\n",
      "  .\n",
      "You can choose the search directory by setting xla_gpu_cuda_data_dir in HloModule's DebugOptions.  For most apps, setting the environment variable XLA_FLAGS=--xla_gpu_cuda_data_dir=/path/to/cuda will work.\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import pandas as pd\n",
    "#import data_structs as ds\n",
    "from data_structs_n import canonicalize_smiles_from_file, construct_vocabulary, write_smiles_to_file\n",
    "from train_prior import pretrain\n",
    "from train_agent import train_agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the dataset and vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data_structs\n",
    "#print(data_structs.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../datasets\n",
      "                                                  SMILES     Tg\n",
      "0      Ic1ccc(nc1)Cc1ccc2c(c1)cc(cc2)Cc1ccc(cn1)N1C(=...  508.0\n",
      "1      O=C1c2cc(ccc2C(=O)N1c1ccc(c(c1Cl)Cl)S(=O)(=O)c...  641.0\n",
      "2      Ic1cc(cc(c1)C(=O)O)C(=O)c1ccc2c(c1)ccc(c2)C(=O...  602.0\n",
      "3      Clc1cc(cc(c1)C(C(F)(F)F)(C(F)(F)F)c1c(C)cc(cc1...  548.0\n",
      "4      Cc1cc(Sc2ccc(nc2)Sc2cc(C)c(c(c2)C)I)cc(c1N1C(=...  502.0\n",
      "...                                                  ...    ...\n",
      "49995  Cc1cc(Cc2ccc(cc2)c2ccc(cc2)Cc2cc(C)c(c(c2)C)I)...  506.0\n",
      "49996  Cc1cc(Cc2ccc(cc2)c2ccc(cc2)Cc2cc(C)c(c(c2)C)I)...  506.0\n",
      "49997  Cc1cc(Cc2ccc(cc2)c2ccc(cc2)Cc2cc(C)c(c(c2)C)I)...  506.0\n",
      "49998  Cc1cc(Cc2ccc(cc2)c2ccc(cc2)Cc2cc(C)c(c(c2)C)I)...  505.0\n",
      "49999  Cc1cc(Cc2ccc(cc2)c2ccc(cc2)Cc2cc(C)c(c(c2)C)I)...  505.0\n",
      "\n",
      "[50000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "data_path = os.path.join(ROOT_DIR, 'datasets')\n",
    "print(data_path)\n",
    "filename = 'Polyimides_synthetic.csv'  #'hce.csv'\n",
    "sep = ','\n",
    "header = 'infer'\n",
    "smile_name = 'SMILES' #'smiles'\n",
    "\n",
    "# dataset load\n",
    "fname = os.path.join(data_path, filename)\n",
    "data = pd.read_csv(fname, sep=sep, header=header)\n",
    "\n",
    "headers =  [\"SMILES\", \"Tg\"]\n",
    "data.columns = headers\n",
    "\n",
    "data = data[headers][:50000]\n",
    "print(data)\n",
    "\n",
    "smiles = data[smile_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading smiles...\n",
      "0 lines processed.\n",
      "5000 lines processed.\n",
      "10000 lines processed.\n",
      "15000 lines processed.\n",
      "20000 lines processed.\n",
      "25000 lines processed.\n",
      "30000 lines processed.\n",
      "35000 lines processed.\n",
      "40000 lines processed.\n",
      "45000 lines processed.\n",
      "50000 SMILES retrieved\n",
      "Constructing vocabulary...\n",
      "Number of characters: 25\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isdir('data'):\n",
    "    os.mkdir('data')\n",
    "\n",
    "# create smi file\n",
    "with open(os.path.join('data', 'data.smi'), 'w') as f:\n",
    "    for smi in smiles:\n",
    "        f.write(smi+'\\n')\n",
    "\n",
    "smiles_file = 'data/data.smi'\n",
    "print(\"Reading smiles...\")\n",
    "smiles_list = canonicalize_smiles_from_file(smiles_file)\n",
    "print(\"Constructing vocabulary...\")\n",
    "voc_chars = construct_vocabulary(smiles_list)\n",
    "write_smiles_to_file(smiles_list, \"data/mols_filtered.smi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrain the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 44.46 GiB of which 832.00 KiB is free. Process 3554031 has 44.45 GiB memory in use. Of the allocated memory 1.44 GiB is allocated by PyTorch, and 10.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOutOfMemoryError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m verbose = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m      3\u001b[39m train_ratio = \u001b[32m0.8\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43mpretrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_ratio\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_ratio\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#, restore_from = \"data/Prior_PI_50k_epochs_8.ckpt\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Tartarus_ChaRNN/Tartarus/models_jupyter/reinvent-benchmarking/train_prior.py:47\u001b[39m, in \u001b[36mpretrain\u001b[39m\u001b[34m(num_epochs, verbose, train_ratio, restore_from)\u001b[39m\n\u001b[32m     44\u001b[39m train_data = DataLoader(train_set, batch_size=\u001b[32m128\u001b[39m, shuffle=\u001b[38;5;28;01mTrue\u001b[39;00m, collate_fn=MolData.collate_fn)\n\u001b[32m     45\u001b[39m valid_data = DataLoader(valid_set, batch_size=\u001b[32m128\u001b[39m, collate_fn=MolData.collate_fn)\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m Prior = \u001b[43mRNN\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvoc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[38;5;66;03m# Can restore from a saved RNN\u001b[39;00m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m restore_from:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Tartarus_ChaRNN/Tartarus/models_jupyter/reinvent-benchmarking/model.py:40\u001b[39m, in \u001b[36mRNN.__init__\u001b[39m\u001b[34m(self, voc)\u001b[39m\n\u001b[32m     38\u001b[39m \u001b[38;5;28mself\u001b[39m.rnn = MultiGRU(voc.vocab_size)\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.cuda.is_available():\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[38;5;28mself\u001b[39m.voc = voc\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/RL-GraphINVENT/RL-GraphINVENT-scores/my-conda-envs/RL-GraphINVENT/lib/python3.12/site-packages/torch/nn/modules/module.py:1065\u001b[39m, in \u001b[36mModule.cuda\u001b[39m\u001b[34m(self, device)\u001b[39m\n\u001b[32m   1048\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcuda\u001b[39m(\u001b[38;5;28mself\u001b[39m: T, device: Optional[Union[\u001b[38;5;28mint\u001b[39m, device]] = \u001b[38;5;28;01mNone\u001b[39;00m) -> T:\n\u001b[32m   1049\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Move all model parameters and buffers to the GPU.\u001b[39;00m\n\u001b[32m   1050\u001b[39m \n\u001b[32m   1051\u001b[39m \u001b[33;03m    This also makes associated parameters and buffers different objects. So\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1063\u001b[39m \u001b[33;03m        Module: self\u001b[39;00m\n\u001b[32m   1064\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1065\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/RL-GraphINVENT/RL-GraphINVENT-scores/my-conda-envs/RL-GraphINVENT/lib/python3.12/site-packages/torch/nn/modules/module.py:915\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    913\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[32m    914\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.children():\n\u001b[32m--> \u001b[39m\u001b[32m915\u001b[39m         \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[32m    918\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[32m    919\u001b[39m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[32m    920\u001b[39m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    925\u001b[39m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[32m    926\u001b[39m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/RL-GraphINVENT/RL-GraphINVENT-scores/my-conda-envs/RL-GraphINVENT/lib/python3.12/site-packages/torch/nn/modules/module.py:942\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    938\u001b[39m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[32m    939\u001b[39m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[32m    940\u001b[39m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[32m    941\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m     param_applied = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    943\u001b[39m p_should_use_set_data = compute_should_use_set_data(param, param_applied)\n\u001b[32m    945\u001b[39m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/RL-GraphINVENT/RL-GraphINVENT-scores/my-conda-envs/RL-GraphINVENT/lib/python3.12/site-packages/torch/nn/modules/module.py:1065\u001b[39m, in \u001b[36mModule.cuda.<locals>.<lambda>\u001b[39m\u001b[34m(t)\u001b[39m\n\u001b[32m   1048\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcuda\u001b[39m(\u001b[38;5;28mself\u001b[39m: T, device: Optional[Union[\u001b[38;5;28mint\u001b[39m, device]] = \u001b[38;5;28;01mNone\u001b[39;00m) -> T:\n\u001b[32m   1049\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Move all model parameters and buffers to the GPU.\u001b[39;00m\n\u001b[32m   1050\u001b[39m \n\u001b[32m   1051\u001b[39m \u001b[33;03m    This also makes associated parameters and buffers different objects. So\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1063\u001b[39m \u001b[33;03m        Module: self\u001b[39;00m\n\u001b[32m   1064\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1065\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._apply(\u001b[38;5;28;01mlambda\u001b[39;00m t: \u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[31mOutOfMemoryError\u001b[39m: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 44.46 GiB of which 832.00 KiB is free. Process 3554031 has 44.45 GiB memory in use. Of the allocated memory 1.44 GiB is allocated by PyTorch, and 10.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "num_epochs = 8 #100\n",
    "verbose = False\n",
    "train_ratio = 0.8\n",
    "pretrain(num_epochs=num_epochs, verbose=verbose, train_ratio=train_ratio) #, restore_from = \"data/Prior_PI_50k_epochs_8.ckpt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start climbing algorithm for REINVENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tartarus import docking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_agent(\n",
    "    scoring_function='tanimoto', #'Tg_score'\n",
    "    batch_size = 500,\n",
    "    n_steps = 10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda list python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run ./reinvent-benchmarking/Pred_Tg/PI_Tg_Pred.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda list sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install sentence-transformers==3.4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install sentence-transformers==3.4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip show transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install transformers==4.28.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SMILES</th>\n",
       "      <th>Tg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33553</th>\n",
       "      <td>O=C(c1ccc2c(c1)C(=O)N(C2=O)I)c1ccc(cn1)C(c1ccc...</td>\n",
       "      <td>455.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9427</th>\n",
       "      <td>Clc1cc(I)cc(c1)Sc1ccc(cc1C)Sc1cc(Cl)cc(c1)N1C(...</td>\n",
       "      <td>455.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>Ic1cc(cc(c1)C(F)(F)F)C(=O)c1ccc2c(c1)[nH]c1c2c...</td>\n",
       "      <td>515.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12447</th>\n",
       "      <td>Cc1ccc(cc1Cc1cc(C)c(c(c1)C)c1c(C)cc(cc1C)Cc1cc...</td>\n",
       "      <td>523.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39489</th>\n",
       "      <td>Ic1ccc(nc1)C(c1ccc2c(c1)ccc(c2)C(c1ccc(cn1)N1C...</td>\n",
       "      <td>466.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33582</th>\n",
       "      <td>Ic1ccc(c(c1)Oc1cc(Oc2ccc(c(c2)N2C(=O)c3c(C2=O)...</td>\n",
       "      <td>479.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31702</th>\n",
       "      <td>Ic1ccc(c(c1)C)Cc1ccc2c(c1)c1cc(ccc1C2(C)C)Cc1c...</td>\n",
       "      <td>510.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38237</th>\n",
       "      <td>Ic1ccc(c(c1)C(C(F)(F)F)(C(F)(F)F)c1ccc(c(c1)Cl...</td>\n",
       "      <td>497.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22358</th>\n",
       "      <td>Clc1cc(cc(c1)C(C(F)(F)F)(C(F)(F)F)c1c(C)cc(cc1...</td>\n",
       "      <td>548.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48246</th>\n",
       "      <td>Ic1cc(C)c(c(c1)C)Oc1ccc(nc1)Oc1c(C)cc(cc1C)N1C...</td>\n",
       "      <td>538.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  SMILES     Tg\n",
       "33553  O=C(c1ccc2c(c1)C(=O)N(C2=O)I)c1ccc(cn1)C(c1ccc...  455.0\n",
       "9427   Clc1cc(I)cc(c1)Sc1ccc(cc1C)Sc1cc(Cl)cc(c1)N1C(...  455.0\n",
       "199    Ic1cc(cc(c1)C(F)(F)F)C(=O)c1ccc2c(c1)[nH]c1c2c...  515.0\n",
       "12447  Cc1ccc(cc1Cc1cc(C)c(c(c1)C)c1c(C)cc(cc1C)Cc1cc...  523.0\n",
       "39489  Ic1ccc(nc1)C(c1ccc2c(c1)ccc(c2)C(c1ccc(cn1)N1C...  466.0\n",
       "...                                                  ...    ...\n",
       "33582  Ic1ccc(c(c1)Oc1cc(Oc2ccc(c(c2)N2C(=O)c3c(C2=O)...  479.0\n",
       "31702  Ic1ccc(c(c1)C)Cc1ccc2c(c1)c1cc(ccc1C2(C)C)Cc1c...  510.0\n",
       "38237  Ic1ccc(c(c1)C(C(F)(F)F)(C(F)(F)F)c1ccc(c(c1)Cl...  497.0\n",
       "22358  Clc1cc(cc(c1)C(C(F)(F)F)(C(F)(F)F)c1c(C)cc(cc1...  548.0\n",
       "48246  Ic1cc(C)c(c(c1)C)Oc1ccc(nc1)Oc1c(C)cc(cc1C)N1C...  538.0\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from Pred_Tg.PI_Tg_Pred import Pred_PI_Tg\n",
    "import numpy as np\n",
    "# Sous-échantillon du trainset pour équilibrer la visualisation, 50 k trop grand !\n",
    "data_sample = data.sample(n=2000, random_state=42)\n",
    "data_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluation de la performance du modele predictif\n",
    "#data_sample['Tg_pred']=data_sample[\"SMILES\"].apply(Pred_PI_Tg) #\n",
    "#rmse = np.sqrt(np.mean((data_sample['Tg_pred'] - data_sample['Tg']) ** 2))\n",
    "#mae = np.mean(np.abs(data_sample['Tg_pred'] - data_sample['Tg']))\n",
    "#print(rmse, mae) #47.47540132795242 30.640225479125977"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.metrics import r2_score\n",
    "#r2 = r2_score(data_sample['Tg'], data_sample['Tg_pred'])\n",
    "#print(r2) #0.30103430066668935"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Pred_Tg.PI_Tg_Pred import run_PolyBERT, finetune_PolyBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 smiles   fitness     score  \\\n",
      "0     Cc1cc(S(=O)(=O)c2ccc(S(=O)(=O)c3cc(C)c(N4C(=O)...  0.296010  0.214925   \n",
      "1     Cc1cc(C(c2ccc(C(c3c(C)cc(I)cc3C)(C(F)(F)F)C(F)...  0.331492  0.330634   \n",
      "2     O=c1c2cc3c(=O)n(-c4ccc(Oc5ccc(I)cn5)nc4)c(=O)c...  0.321152  0.297752   \n",
      "3     Cc1ccc(C(c2ccc(C(c3cc(I)ccc3C)(C(F)(F)F)C(F)(F...  0.000000 -0.678468   \n",
      "4     Cc1ccc(N2C(=O)c3cccc(-c4ccc5c(c4)C(=O)N(I)C5=O...  0.423963  0.584891   \n",
      "...                                                 ...       ...       ...   \n",
      "4737  Cc1c(I)cccc1Sc1ccc(Sc2cccc(-n3c(=O)c4cc5cc4c(=...  0.000000 -0.643401   \n",
      "4738  Cc1cc(-c2cc(C)c(Sc3ccc(N4C(=O)c5ccc(-c6ccc7c(c...  0.386343  0.353131   \n",
      "4739  Cc1c(Sc2ccc(N3C(=O)c4ccc(-c5ccc6c(c5)C(=O)N(I)...  0.000000 -0.643401   \n",
      "4740  Cc1cc(I)cc(C)c1Sc1ccc(Cc2c(C)cc(N3C(=O)c4ccc(-...  0.385627  0.351291   \n",
      "4741  Cc1cc(C(c2ccc(-c3ccc(C(c4ccc(-n5c(=O)cn6c(=O)c...  0.000000 -0.643401   \n",
      "\n",
      "      generation  \n",
      "0            0.0  \n",
      "1            0.0  \n",
      "2            0.0  \n",
      "3            0.0  \n",
      "4            0.0  \n",
      "...          ...  \n",
      "4737         9.0  \n",
      "4738         9.0  \n",
      "4739         9.0  \n",
      "4740         9.0  \n",
      "4741         9.0  \n",
      "\n",
      "[4742 rows x 4 columns]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'data_sample' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m PI_generation = pd.read_csv(\u001b[33m\"\u001b[39m\u001b[33mdata/results/run_PI_50k_11_Juin_2025/results.csv\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(PI_generation)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m data_sample[\u001b[33m'\u001b[39m\u001b[33mPB\u001b[39m\u001b[33m'\u001b[39m]=\u001b[43mdata_sample\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33mSMILES\u001b[39m\u001b[33m\"\u001b[39m].apply(finetune_PolyBERT) \u001b[38;5;66;03m# (trainset)\u001b[39;00m\n\u001b[32m     10\u001b[39m data_sample[\u001b[33m'\u001b[39m\u001b[33mPB\u001b[39m\u001b[33m'\u001b[39m] = data_sample[\u001b[33m'\u001b[39m\u001b[33mPB\u001b[39m\u001b[33m'\u001b[39m].apply(\u001b[38;5;28meval\u001b[39m)\n\u001b[32m     11\u001b[39m data_sample[\u001b[33m'\u001b[39m\u001b[33mPB\u001b[39m\u001b[33m'\u001b[39m] = data_sample[\u001b[33m'\u001b[39m\u001b[33mPB\u001b[39m\u001b[33m'\u001b[39m].apply(np.array)\n",
      "\u001b[31mNameError\u001b[39m: name 'data_sample' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "PI_generation = pd.read_csv(\"data/results/run_PI_50k_11_Juin_2025/results.csv\")\n",
    "print(PI_generation)\n",
    "\n",
    "data_sample['PB']=data_sample[\"SMILES\"].apply(finetune_PolyBERT) # (trainset)\n",
    "data_sample['PB'] = data_sample['PB'].apply(eval)\n",
    "data_sample['PB'] = data_sample['PB'].apply(np.array)\n",
    "\n",
    "PI_generation['PB'] = PI_generation[\"smiles\"].apply(finetune_PolyBERT) # un peu plus de 400 par generation, [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0] \n",
    "PI_generation['PB'] = PI_generation['PB'].apply(eval)\n",
    "PI_generation['PB'] = PI_generation['PB'].apply(np.array)\n",
    "\n",
    "# Liste des générations à tracer\n",
    "generations = [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0]\n",
    "\n",
    "# Prépare la figure\n",
    "fig, axes = plt.subplots(2, 5, figsize=(25, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, gen in enumerate(generations):\n",
    "    ax = axes[idx]\n",
    "\n",
    "    # Extraire les embeddings\n",
    "    X_train = np.vstack(data_sample['PB'].values)\n",
    "    X_gen = np.vstack(PI_generation[PI_generation['generation'] == gen]['PB'].values)\n",
    "\n",
    "    # Créer un tableau combiné\n",
    "    X = np.vstack([X_train, X_gen])\n",
    "    labels = np.array(['train'] * len(X_train) + [f'gen_{int(gen)}'] * len(X_gen))\n",
    "\n",
    "    # Projection t-SNE\n",
    "    tsne = TSNE(n_components=2, random_state=42, perplexity=30)\n",
    "    X_tsne = tsne.fit_transform(X)\n",
    "\n",
    "    # Plot\n",
    "    ax.scatter(X_tsne[labels == 'train', 0], X_tsne[labels == 'train', 1], alpha=0.3, label='Train', s=10)\n",
    "    ax.scatter(X_tsne[labels != 'train', 0], X_tsne[labels != 'train', 1], alpha=0.7, label=f'Gen {int(gen)}', s=10)\n",
    "    ax.set_title(f\"t-SNE Projection: Generation {int(gen)}\")\n",
    "    ax.legend()\n",
    "    print('ok')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:RL-GraphINVENT]",
   "language": "python",
   "name": "conda-env-RL-GraphINVENT-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
